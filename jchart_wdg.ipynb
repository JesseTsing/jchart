{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b9ac42d-0160-4599-adc7-f0f84962f5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "# import logging\n",
    "\n",
    "class OutputWidgetHandler:\n",
    "    \"\"\" Custom logging handler sending logs to an output widget \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        # super(OutputWidgetHandler, self).__init__(*args, **kwargs)\n",
    "        layout = {\n",
    "            'width': '100%',\n",
    "            'height': '160px',\n",
    "            'border': '1px solid black',\n",
    "#             'overflow_y':'hidden',\n",
    "            'overflow_y':'scroll',\n",
    "        }\n",
    "        self.out = widgets.Textarea(layout=layout)\n",
    "        self.lines = list()\n",
    "        self.maxlines = 999\n",
    "    \n",
    "    def info(self,msg_str):\n",
    "        self.emit(msg_str,'INFO')\n",
    "    \n",
    "    def warn(self,msg_str):\n",
    "        self.emit(msg_str,'WARN')\n",
    "    \n",
    "    def error(self,msg_str):\n",
    "        self.emit(msg_str,'ERROR')\n",
    "    \n",
    "    def emit(self, record,level):\n",
    "        \"\"\" Overload of logging.Handler method \"\"\"\n",
    "        formatted_record = f'{datetime.now()} - [{level}] {record}'\n",
    "        # if isinstance(record,str):\n",
    "        #     formatted_record = f'{datetime.now()} - [{level}] {record}'\n",
    "        # else:\n",
    "        #     formatted_record = self.format(record)\n",
    "        \n",
    "        self.lines.append(formatted_record)\n",
    "        # new_output = [ formatted_record+'\\n',]\n",
    "        \n",
    "#         self.out.outputs = (new_output, )\n",
    "\n",
    "        # alllen = 0\n",
    "        # oldoutputs = list()\n",
    "        # for output in self.out.outputs:\n",
    "        #     alllen += len(output['text'])\n",
    "        #     if alllen > 10240:\n",
    "        #         break\n",
    "        #     oldoutputs.append(output)\n",
    "        # self.out.outputs = (new_output, ) + tuple(oldoutputs) \n",
    "        self.lines = self.lines[-self.maxlines:]\n",
    "        self.out.value = '\\n'.join(reversed(self.lines))\n",
    "\n",
    "    def show_logs(self):\n",
    "        \"\"\" Show the logs \"\"\"\n",
    "        # display(self.out)\n",
    "        pass\n",
    "\n",
    "    def clear_logs(self):\n",
    "        \"\"\" Clear the current logs \"\"\"\n",
    "        # self.out.clear_output()\n",
    "        self.out.clear.value=''\n",
    "\n",
    "\n",
    "\n",
    "logger = OutputWidgetHandler()\n",
    "# handler.setFormatter(logging.Formatter('%(asctime)s  - [%(levelname)s] %(message)s'))\n",
    "# logger.addHandler(handler)\n",
    "# logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89c8fe08-4c84-46a4-93e4-39a9dca04c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2acb50a-4ca0-4844-9374-5f1eb832d507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import feather\n",
    "import zmq\n",
    "import orjson\n",
    "from copy import deepcopy\n",
    "import ipywidgets as widgets\n",
    "from threading import Thread\n",
    "from datetime import datetime,timedelta\n",
    "import time\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os,sys,glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pylab import mpl\n",
    "    \n",
    "mpl.rcParams['font.family'] = 'kaiti'\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "from progressbar import ProgressBar\n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from functools import lru_cache\n",
    "\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from matplotlib.widgets import SpanSelector\n",
    "from collections import Counter\n",
    "from ipywidgets import GridspecLayout\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "890963a9-6f29-4c31-b356-55acfe672cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_acc = widgets.Accordion(children=[logger.out], )\n",
    "error_acc.set_title(0,'LogViewer')\n",
    "\n",
    "\n",
    "\n",
    "asset_category = widgets.Dropdown(options=['stock','index','FUT','OPT','FX',],value='stock',layout=widgets.Layout(width='120px',))\n",
    "underlying_list = widgets.Select(options=list(),layout=widgets.Layout(width='120px',height='900px'))\n",
    "range_list = widgets.SelectMultiple(options=list(),layout=widgets.Layout(width='120px',height='900px'))\n",
    "# comb_list = widgets.Select(options=list(),layout=widgets.Layout(width='200px',height='300px'))\n",
    "\n",
    "reload_but = widgets.Button(description='Reset',layout=widgets.Layout(width='80px',))\n",
    "\n",
    "comb_but =  widgets.Button(description='Combine',layout=widgets.Layout(width='80px',))\n",
    "redo_but =  widgets.Button(description='Redo',layout=widgets.Layout(width='80px',))\n",
    "\n",
    "sample_trades_slider = widgets.IntSlider(description='Trds',value=5,min=1,max=240,step=1,layout=widgets.Layout(width='240px',))\n",
    "sample_min_slider = widgets.IntSlider(description='Mins',value=1,min=1,max=240,step=1,layout=widgets.Layout(width='240px',))\n",
    "comb_range_slider = widgets.IntSlider(description='Rng(â€°)',value=5,min=1,max=100,step=1,layout=widgets.Layout(width='240px',))\n",
    "\n",
    "resample_but = widgets.Button(description='Resample',layout=widgets.Layout(width='80px',))\n",
    "start_date = widgets.DatePicker(value=datetime.now().date() - relativedelta(days=5),layout=widgets.Layout(width='160px',))\n",
    "end_date = widgets.DatePicker(value=datetime.now().date(),layout=widgets.Layout(width='160px',))\n",
    "# underlying_tab.datamodel = rt.DataFrameDataModel(pd.DataFrame())\n",
    "\n",
    "# abandon jcplot Output cause capture not work, using canvas\n",
    "# jcplot = widgets.Output() #layout=widgets.Layout(width='1200px',height='600px')) # rt.RegularTableWidget(pd.DataFrame(),)\n",
    "gs = GridspecLayout(1, 1, \n",
    "                width='1200px',\n",
    "                   )\n",
    "\n",
    "main_tabs = widgets.VBox([widgets.HBox([asset_category,reload_but,sample_trades_slider,sample_min_slider,comb_range_slider,\n",
    "                                        start_date, end_date,\n",
    "                                        resample_but,  comb_but, redo_but, ]), \n",
    "                          widgets.HBox([underlying_list, range_list,\n",
    "                                        gs,\n",
    "                                       ])])\n",
    "main_form = widgets.VBox([error_acc,main_tabs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "480b0fbb-61cd-40ca-b492-9274ad2fa9d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e47355a-2f17-437b-84d7-e9d5fdb6fa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_productID(code,):\n",
    "    for idx,s in enumerate(code):\n",
    "        if s.isdigit():\n",
    "            return code[:idx]\n",
    "    return ''\n",
    "\n",
    "    \n",
    "\n",
    "def get_opt_underlying_strike(opt_code, callputchar):\n",
    "    suffix = opt_code[2:].upper()\n",
    "    x = suffix.find(callputchar)\n",
    "    if x < 0:\n",
    "        raise Exception('no c or p found')\n",
    "    \n",
    "    strike_str = suffix[x+1:]\n",
    "    under = opt_code[:2]+suffix[:x]\n",
    "    if under.startswith('IO'):\n",
    "        under = 'IF' + under[2:]\n",
    "    return under, int(strike_str)\n",
    "\n",
    "def get_contract(fp):\n",
    "    fn = os.path.basename(fp)\n",
    "    contract_code_ori,tday = fn.split('.csv')[0].split('_')\n",
    "    contract_code = contract_code_ori.replace('-','')\n",
    "    # first 2 chars productid?\n",
    "    suffix = contract_code[2:].upper()\n",
    "    info = dict()\n",
    "    info['fp'] = fp\n",
    "    info['tday'] = tday\n",
    "    info['original_contract_code'] = contract_code_ori\n",
    "    if 'C' in suffix:\n",
    "        info['iscall'] = True\n",
    "        info['contract_class'] = 'OPT'\n",
    "    elif 'P' in suffix:\n",
    "        info['iscall'] = False\n",
    "        info['contract_class'] = 'OPT'\n",
    "    else:\n",
    "        info['contract_class'] = 'FUT'\n",
    "    \n",
    "    info['productID'] = get_productID(contract_code)\n",
    "    if info['contract_class'] == 'OPT':\n",
    "        if info['iscall']:\n",
    "            underlying,strike = get_opt_underlying_strike(contract_code,'C')\n",
    "        else:\n",
    "            underlying,strike = get_opt_underlying_strike(contract_code,'P')\n",
    "        info['underlying'] = underlying\n",
    "        info['strike'] = strike\n",
    "    elif info['contract_class'] == 'FUT':\n",
    "        info['underlying'] = contract_code\n",
    "    return info\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee056d2b-f914-47db-8122-1e56e3451459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# today_contract_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae7a506c-b69b-40d4-9f56-c64c0ddc5ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     today_contract_df = today_contract_df[today_contract_df['contract_class']=='OPT']\n",
    "#     today_contract_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1e45fc3-e0a7-4f01-8af9-6780e1053309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store data segments\n",
    "time_chains_dict = dict()\n",
    "# store current figure param\n",
    "time_chains_key_list = list()\n",
    "# store for triangle starts X, for SpanSelector\n",
    "last_dist_starts = list()\n",
    "redo_list = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3412fd-cc7f-45b4-813e-09b21fc3b56d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fff313b-1c85-4ce2-9004-8028ea08ca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store ranges\n",
    "# splitted_range_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56bfcaba-1f3e-4d95-8ea2-9978e5a53530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store list of ranges\n",
    "# combined_range_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "973a7a57-6c6d-4e0b-aa9b-16bb12580325",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_rootdir = '/home/jesse/DataLinks/104_mntdisk1jesse/ctpdata_reformat/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "690c2355-fe84-4a6b-b305-0cf3b84c69cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "forex_rootdir = '/home/jesse/DataLinks/104_mntdisk1jesse/histdata.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50429c1d-39a1-4920-adbf-cce86fba3ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def on_reload(b):\n",
    "    # global splitted_range_dict\n",
    "    logger.info(\"loading stock infos\")\n",
    "    asset_cat = asset_category.value\n",
    "    if asset_cat in ['stock','index',]:\n",
    "        stock_info_df = pd.read_parquet(f'/home/jesse/DataLinks/StockDB/JQData_static(allSecuritiesInfo)/{asset_cat}.parquet')\n",
    "        stock_list = sorted(stock_info_df['jq_code'].unique().tolist())\n",
    "        underlying_list.options = stock_list\n",
    "    elif asset_cat in ['FUT','OPT',]:\n",
    "        \n",
    "        fps_lastyear = glob.glob(os.path.join(future_rootdir,f'{datetime.now().year-1}*','*.csv*'))\n",
    "        fps_thisyear = glob.glob(os.path.join(future_rootdir,f'{datetime.now().year}*','*.csv*'))\n",
    "        fps = fps_lastyear + fps_thisyear\n",
    "        len(fps)\n",
    "        today_contract_df = pd.DataFrame([get_contract(item) for item in fps]) #get_contract('MA003P2025_20191223'),get_contract('i2002-P-620_20191223')\n",
    "        today_contract_df.shape\n",
    "\n",
    "        today_contract_df = today_contract_df.drop_duplicates(subset=['original_contract_code'])\n",
    "        sel_df = today_contract_df[today_contract_df['contract_class']==asset_cat]\n",
    "        underlying_list.options = sorted(sel_df['original_contract_code'].unique().tolist())\n",
    "    elif asset_cat in ['FX']:\n",
    "        fps = glob.glob(os.path.join(forex_rootdir,'DAT_ASCII_*.csv*'))\n",
    "        underlying_list.options = sorted(pd.Series([os.path.basename(fp).split('_')[2] for fp in fps]).unique().tolist())\n",
    "    # underlying_list.value = None\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "961d3a86-9a75-443e-a512-22a3ea356d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6cf9843-a4d9-4e2a-8147-b8ebec4e560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_but.on_click(on_reload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e6b53e8-335d-457a-bb23-e264580898ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inst = '000001.XSHE'\n",
    "\n",
    "# alldf['split_key'] = alldf['timestamp'].apply(dt2int) * 100\n",
    "# alldf['comb_key'] = alldf['split_key'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c15ae53-e483-452a-a09c-5f03de896747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bae0a7a-46b1-4f45-892c-4b590349d362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58e2b15d-13d2-44aa-a660-d091a643a05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt2int(x):\n",
    "    return int(x.year * 10**8 + x.month * 10**6 + x.day * 10**4 + x.hour * 10**2 + x.minute)\n",
    "    \n",
    "def int2dt(dint):\n",
    "    dstr = str(int(dint))\n",
    "    return datetime(int(dstr[:4]), int(dstr[4:6]), int(dstr[6:8]), int(dstr[8:10]), int(dstr[10:12]), )\n",
    "\n",
    "def dtsampler(_dt_list, comb_range=1):\n",
    "    # dt_list in min\n",
    "    dt_list = list(map(dt2int, _dt_list))\n",
    "    res_key = list()\n",
    "    count = 0\n",
    "    lts = None\n",
    "    lastdtmin1_open = None\n",
    "    for dtmin1 in dt_list:\n",
    "        if dtmin1 != lts:   \n",
    "            if count == comb_range:\n",
    "                count = 0\n",
    "                lastdtmin1_open = None\n",
    "            if lastdtmin1_open is None:\n",
    "                lastdtmin1_open = dtmin1\n",
    "            lts = dtmin1    \n",
    "            count +=1\n",
    "            \n",
    "        res_key.append(lastdtmin1_open)\n",
    "        # if dtmin1 != lts:\n",
    "            # reset count and lastdt\n",
    "            \n",
    "                # lastdtmin1_open = None\n",
    "            # lts = dtmin1\n",
    "    return res_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d07cde6-b8c6-48e1-b4b6-c2631bc658e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdb6e7f5-b98b-4902-85e4-ea72ac49bfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtsampler(pd.to_datetime(['2021-01-01 09:30:00',\n",
    "#                           '2021-01-01 09:30:00',\n",
    "#                           '2021-01-01 09:30:03',\n",
    "#                           '2021-01-01 09:30:04',\n",
    "#                           '2021-01-01 09:31:01',\n",
    "#                           '2021-01-01 09:31:02',\n",
    "#                           '2021-01-01 09:32:01',\n",
    "#                           '2021-01-01 09:32:01',\n",
    "#                           '2021-01-01 09:32:01',\n",
    "#                           '2021-01-01 09:33:01',\n",
    "#                           '2021-01-01 09:33:02',\n",
    "#                           '2021-01-01 09:33:03',\n",
    "#                           '2021-01-01 09:33:05',\n",
    "#                           '2021-01-01 09:34:00',\n",
    "#                          ]),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29d62000-cf57-47a8-bab0-1c1706ffb88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1,2,1,1,13].index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181f93e8-d31e-4275-ad0c-882ef912aa7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b636632-6b99-4d7b-8efe-e3d11217c622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_chains[0]\n",
    "# pd.Series([1,2,3])[pd.Series([1,2,3]).mod(2).eq(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf84209d-8e26-41d2-ba34-64c5da2f8df3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d5be3fc-6385-4fb9-9c34-8e5540609e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicates current span selection start and end\n",
    "cur_last_dist_st, cur_last_dist_ed = 0,0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "605a543b-dec0-4f60-9e0c-538766ee6159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def span_onselect(xmin, xmax):\n",
    "    global cur_last_dist_st, cur_last_dist_ed\n",
    "    # store combined time ranges\n",
    "    indmin, indmax = np.searchsorted(last_dist_starts, (xmin, xmax))\n",
    "    indmin -= 1\n",
    "    indmax -= 1\n",
    "    indmin = max(0, indmin)\n",
    "    indmax = min(len(last_dist_starts) - 1, indmax)    \n",
    "    cur_last_dist_st, cur_last_dist_ed = last_dist_starts[indmin], last_dist_starts[indmax]\n",
    "    logger.info(f'selected indmin,indmax:st,ed {indmin} {indmax} {last_dist_starts[indmin]} {last_dist_starts[indmax]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095d985d-029d-441f-902f-4744bab8894d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf47657b-25bf-4e95-8c91-d40da807b136",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,span,ax = None,None,None\n",
    "_siz = (12,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bab615f2-7a7f-48a3-a671-8ea4cd1a39f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refresh_plots(b):\n",
    "    global time_chains_key_list,redo_list,last_dist_starts,span,ax,gs,fig\n",
    "    is_redo = False\n",
    "    if isinstance(b,str):\n",
    "        if b == 'redo':\n",
    "            is_redo=True\n",
    "            logger.info(f\"== redolist bef:len {len(redo_list)} {[item['ts_list'] for item in redo_list[-1]]}\")\n",
    "            redo_list.pop()\n",
    "            logger.info(f\"== redolist aft:len {len(redo_list)} {[item['ts_list'] for item in redo_list[-1]]}\")\n",
    "            time_chains_key_list = deepcopy(redo_list[-1])\n",
    "            # logger.info(f\"--- redo_list:{redo_list}\")\n",
    "    logger.info(f\"ooo ts_list:{[item['ts_list'] for item in time_chains_key_list]}\")\n",
    "    # global fig, fig_key \n",
    "    # logger.info('start ploting')\n",
    "    buckets = list()\n",
    "    last_flag_in_group = False\n",
    "    # ts must be sorted!!!    \n",
    "    if len(time_chains_key_list) > 0:\n",
    "        for item in time_chains_key_list:\n",
    "            if is_redo:\n",
    "                buckets.append(item['ts_list'])\n",
    "            elif not last_flag_in_group and item['last_dist_start'] >= cur_last_dist_st and item['last_dist_start'] <= cur_last_dist_ed:\n",
    "                last_flag_in_group = True\n",
    "                buckets.append(list())\n",
    "                buckets[-1] = item['ts_list']\n",
    "            elif last_flag_in_group and item['last_dist_start'] >= cur_last_dist_st and item['last_dist_start'] <= cur_last_dist_ed:\n",
    "                # continue add points into current buckets\n",
    "                buckets[-1].extend(item['ts_list'])\n",
    "            elif last_flag_in_group and item['last_dist_start'] > cur_last_dist_ed:\n",
    "                buckets.append(item['ts_list'])\n",
    "                # jump out current buckets\n",
    "                last_flag_in_group = False\n",
    "            else:\n",
    "                # add original range\n",
    "                buckets.append(item['ts_list'])\n",
    "            \n",
    "    else:\n",
    "        # first plot\n",
    "        for ts in sorted(range_list.options):\n",
    "            buckets.append([ts])\n",
    "    # for ts in sorted(range_list.options):\n",
    "    #     if not last_flag_in_group and ts in range_list.value:\n",
    "    #         # enter a new combined range\n",
    "    #         last_flag_in_group = True\n",
    "    #         buckets.append(list())\n",
    "    #     elif last_flag_in_group and ts in range_list.value:\n",
    "    #         # continue add points into current buckets\n",
    "    #         buckets[-1].append(ts)\n",
    "    #     elif last_flag_in_group and ts not in range_list.value:\n",
    "    #         buckets[-1].append(ts)\n",
    "    #         # jump out current buckets\n",
    "    #         last_flag_in_group = False\n",
    "    #     else:\n",
    "    #         # add original range\n",
    "    #         buckets.append([ts])            \n",
    "    \n",
    "        \n",
    "    # force close figure\n",
    "    if fig is None:\n",
    "        # plt.close(fig=fig)\n",
    "        fig, ax = plt.subplots()  \n",
    "        gs[0,0] = fig.canvas\n",
    "        \n",
    "        fig.set_size_inches(_siz)\n",
    "        fig.canvas.toolbar_visible = False\n",
    "        fig.canvas.header_visible = False\n",
    "        # fig.canvas.layout.min_width = f'{_siz[0]}in'\n",
    "        # fig.canvas.layout.min_height = f'{_siz[1]}in'\n",
    "        \n",
    "    # before every refreshing\n",
    "    ax.clear()\n",
    "     \n",
    "    if len(time_chains_key_list) > 0:             \n",
    "        time_chains_key_list = list()\n",
    "        \n",
    "    last_dist_start = 0\n",
    "    for ts_list in buckets:\n",
    "        # start delta\n",
    "        dist = dict()\n",
    "        mark_tri = False\n",
    "        # len > 1, combined range !!, triangle markable        \n",
    "        if len(ts_list) > 0:\n",
    "            mark_tri = True\n",
    "\n",
    "        # combined subdfs are in but_l\n",
    "        open_prc = None\n",
    "        close_prc = None\n",
    "        # adf = pd.concat([time_chains_dict[_ts] for _ts in ts_list])\n",
    "        prc_vector = np.concatenate([time_chains_dict[_ts] for _ts in ts_list])\n",
    "        # open_prc, close_prc = adf['tradp'].iloc[0],adf['tradp'].iloc[-1]\n",
    "        open_prc, close_prc = prc_vector[0], prc_vector[-1]\n",
    "        # dist = Counter(adf['tradp'])\n",
    "        dist = Counter(prc_vector)\n",
    "        \n",
    "\n",
    "        # for pp in dist.keys():\n",
    "        #     plt.plot([last_dist_start+1, last_dist_start+1+dist[pp]],[pp,pp],'b')\n",
    "        _bins = ax.hist(prc_vector, bins=max(10,int((prc_vector.max()-prc_vector.min())/sample_trades_slider.value)), orientation='horizontal', bottom=last_dist_start, color='b')\n",
    "        _bins_cnt = _bins[0].max()\n",
    "        \n",
    "        if mark_tri:\n",
    "            # cal tri endpoints and plot\n",
    "            balanced_prc = -1\n",
    "            balanced_cnt = -1\n",
    "            # find max counts' price level\n",
    "            for _prc,_cnt in dist.items():\n",
    "                if _cnt > balanced_cnt:\n",
    "                    balanced_cnt = _cnt\n",
    "                    balanced_prc = _prc\n",
    "\n",
    "\n",
    "            up_p = max(dist.keys())\n",
    "            dn_p = min(dist.keys())\n",
    "            \n",
    "            dn_p = balanced_prc - (up_p - balanced_prc)\n",
    "            \n",
    "            # logger.info(f'mirror to DN:{dn_p} Mid:{balanced_prc} UP:{up_p}')\n",
    "            markerup = 'r'\n",
    "            markerdn = 'r-.'\n",
    "            markerbl = 'y'\n",
    "            # mirror point is in bottom\n",
    "            # if up_p - balanced_prc > balanced_prc - dn_p:\n",
    "            #     dn_p = balanced_prc - (up_p - balanced_prc)\n",
    "            #     logger.info(f'mirror to DN:{dn_p} Mid:{balanced_prc} UP:{up_p}')\n",
    "            #     markerup = 'r'\n",
    "            #     markerdn = 'r-.'\n",
    "            # elif up_p - balanced_prc < balanced_prc - dn_p:\n",
    "            #     up_p = balanced_prc + (balanced_prc - dn_p)\n",
    "            #     logger.info(f'mirror to UP:{up_p} Mid:{balanced_prc} DN:{dn_p}')\n",
    "            #     markerup = 'r-.'\n",
    "            #     markerdn = 'r'\n",
    "\n",
    "            # plot mirror triangle\n",
    "            ax.plot([last_dist_start+1, last_dist_start+1+_bins_cnt],[up_p, balanced_prc],markerup)\n",
    "            ax.plot([last_dist_start+1, last_dist_start+1+_bins_cnt],[dn_p, balanced_prc],markerdn)\n",
    "            ax.plot([last_dist_start+1, last_dist_start+1+_bins_cnt],[balanced_prc, balanced_prc],markerbl)\n",
    "            # ax.annotate(f'{round(balanced_prc,4)}', (last_dist_start+_bins_cnt/2, balanced_prc) )\n",
    "            ax.text(last_dist_start+_bins_cnt/2, balanced_prc,f'{round(balanced_prc,4)}')\n",
    "        # plot open close markers\n",
    "        ax.plot([last_dist_start+1],[open_prc],'ro', markersize=3)\n",
    "        ax.plot([last_dist_start+1],[close_prc],'go', markersize=3)\n",
    "            # plt.pause(0.1)\n",
    "            # logger.info(f'')-\n",
    "        # cal next X start point\n",
    "        max_counts = max(dist.values())\n",
    "        time_chains_key_list.append({\n",
    "            # 'ts_st':adf['timestamp'].iloc[0],\n",
    "            # 'ts_ed':adf['timestamp'].iloc[-1],\n",
    "            # 'balanced_prc':balanced_prc,\n",
    "            # 'balanced_cnt':balanced_cnt,\n",
    "            # '_bins_cnt':_bins_cnt,\n",
    "            'last_dist_start':last_dist_start,\n",
    "            'ts_list':ts_list,\n",
    "        })\n",
    "        \n",
    "        \n",
    "        last_dist_start += _bins_cnt\n",
    "    # update global starts for SpanSelector \n",
    "    last_dist_starts = [item['last_dist_start'] for item in time_chains_key_list]\n",
    "    logger.info(f\"DONE ploting last_dist_starts:{last_dist_starts}\")\n",
    "    logger.info(f\"DONE ploting ts_lists:{[item['ts_list'] for item in time_chains_key_list]}\")\n",
    "    # add to action_hist\n",
    "    if not is_redo:\n",
    "        redo_list.append(deepcopy(time_chains_key_list))  \n",
    "    redo_but.description=f'Redo({len(redo_list)})'\n",
    "    # logger.info('DONE ploting')\n",
    "\n",
    "    # fig.canvas.draw_idle()\n",
    "    span = SpanSelector(\n",
    "                            ax,\n",
    "                            span_onselect,\n",
    "                            \"horizontal\",\n",
    "                            useblit=True, # Set useblit=True on most backends for enhanced performance.\n",
    "                            props=dict(alpha=0.5, facecolor=\"blue\"),\n",
    "                            interactive=True,\n",
    "                            # drag_from_anywhere=True,\n",
    "                            )\n",
    "    fig.set_size_inches(_siz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d485f47a-7887-46d0-b75b-ab561b097a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_comb(b):\n",
    "    if cur_last_dist_st == cur_last_dist_ed:\n",
    "        logger.error(\"MUST select a ragion > 1 triagles!!!\")\n",
    "    else:\n",
    "        refresh_plots(None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2abeb0a9-a698-4934-8e4c-13ee4a9980f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_but.on_click(on_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87894b3-d2d1-46aa-81cc-ffecde4887b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "368b1bf0-5cf6-4dd6-b457-6fb7588fab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bp(ser):\n",
    "    dist = Counter(ser)\n",
    "    # cal tri endpoints and plot\n",
    "    balanced_prc = -1\n",
    "    balanced_cnt = -1\n",
    "    # find max counts' price level\n",
    "    for _prc,_cnt in dist.items():\n",
    "        if _cnt > balanced_cnt:\n",
    "            balanced_cnt = _cnt\n",
    "            balanced_prc = _prc\n",
    "    return balanced_prc,balanced_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e95e382b-5dc1-4c22-8f51-52faf3fcabcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max({9:45,10:55}.values())\n",
    "def dt2hms(dt):\n",
    "    return dt.hour*10000+dt.minute*100+dt.second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7fbcfde6-122a-4399-a199-52cf54335f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "auto_make_tri_mode = 'sym_tri'\n",
    "auto_make_tri_mode = 'tri_done'\n",
    "auto_make_tri_mode = ''\n",
    "# assert not auto_make_tri_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "93ae5829-1999-4ece-b828-f7cb6f701ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ctp_tick(fp):\n",
    "    df = pd.read_csv(fp,).rename(columns={'LastPrice':'tradp','local_timestamp':'timestamp'})\n",
    "    df = df[['tradp','timestamp']]\n",
    "    df.loc[:,'timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "393b2519-6569-45da-98de-b3b36a6c931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_select_inst(b):\n",
    "    global time_chains_dict,time_chains_key_list,last_dist_starts,redo_list\n",
    "    if isinstance(b,str):\n",
    "        inst = b\n",
    "    else:\n",
    "        inst = b.new\n",
    "    \n",
    "    logger.info(f'loading single sym:{inst}')\n",
    "    time_chains_dict = dict()\n",
    "    dfs = list()\n",
    "    if asset_category.value in ['stock','index']:\n",
    "        if asset_category.value == 'stock':\n",
    "            indir = '/home/jesse/DataLinks/l2_data_combined_feather_splitted_jl/trade_data/'\n",
    "            cols = ['securityid','timestamp','tradp','tradv']\n",
    "    \n",
    "        elif asset_category.value == 'index':\n",
    "            indir = '/home/jesse/DataLinks/l2_data_combined_feather_splitted_jl/index_data/'\n",
    "            cols = ['securityid','timestamp','lastp','tradv']\n",
    "        for tdaystr in sorted(os.listdir(indir)):\n",
    "            tday = pd.to_datetime(tdaystr).date()\n",
    "            if tday < start_date.value or tday > end_date.value:\n",
    "                continue\n",
    "            fp = os.path.join(indir,tdaystr,f'{inst}_{tdaystr}.feather')\n",
    "            if not os.path.isfile(fp):\n",
    "                logger.error(f'{fp} not exsist')\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                df = pd.read_feather(fp,columns=cols).rename(columns={'lastp':'tradp',})\n",
    "\n",
    "                cond = df['timestamp'].apply(lambda dt: (93000 <= dt2hms(dt) <= 113000) or (130000 <= dt2hms(dt) < 150005) )\n",
    "                df = df[cond]\n",
    "                logger.info(f'loading {fp}')\n",
    "                # df = df[df['securityid'] == inst]\n",
    "                # df['date'] = str(tday.date())\n",
    "                dfs.append(df)\n",
    "            except:\n",
    "                logger.error(f'{inst} not in {fp}')\n",
    "    elif asset_category.value in ['FUT','OPT']:        \n",
    "        for tdaystr in sorted(os.listdir(future_rootdir)):\n",
    "            subdir = os.path.join(future_rootdir,tdaystr)\n",
    "            if not os.path.isdir(subdir) or not len(tdaystr) == 8:\n",
    "                continue\n",
    "                \n",
    "            tday = pd.to_datetime(tdaystr).date()\n",
    "            if tday < start_date.value or tday > end_date.value:\n",
    "                continue            \n",
    "            \n",
    "            fps = glob.glob(os.path.join(future_rootdir,tdaystr,f'{inst}_{tdaystr}.csv*'))\n",
    "            if len(fps) < 1:\n",
    "                logger.error(f'{inst}_{tdaystr} not exsist')\n",
    "                continue\n",
    "            fp = fps[0]\n",
    "\n",
    "            try:\n",
    "                df = read_ctp_tick(fp)\n",
    "\n",
    "                # cond = df['timestamp'].apply(lambda dt: (93000 <= dt2hms(dt) <= 113000) or (130000 <= dt2hms(dt) < 150005) )\n",
    "                # df = df[cond]\n",
    "                logger.info(f'loading {fp}')\n",
    "                # df = df[df['securityid'] == inst]\n",
    "                # df['date'] = str(tday.date())\n",
    "                dfs.append(df)\n",
    "            except:\n",
    "                logger.error(f'{inst} not in {fp}')\n",
    "        # add realtime tick data!!!!\n",
    "        if end_date.value == pd.to_datetime(datetime.now().date()):\n",
    "            __lastdaystr = sorted([item for item in os.listdir('/home/jesse/data_recorder/') if len(item) == 8 ])[-1]\n",
    "            realtimefp = f'/home/jesse/data_recorder/{__lastdaystr}/{inst}_{__lastdaystr}.csv'\n",
    "            logger.info(f'reading realtime csv:{realtimefp}')\n",
    "            try:\n",
    "                dfs.append(read_ctp_tick(realtimefp))\n",
    "            except:\n",
    "                logger.error(f'{inst} has no realtimefp:{realtimefp}')\n",
    "            \n",
    "    elif asset_category.value in ['FX']:\n",
    "        fps = sorted(glob.glob(os.path.join(forex_rootdir,f'DAT_ASCII_{inst}_*.csv*')))\n",
    "        for fp in fps:\n",
    "            st = os.path.basename(fp)[-10:-4]\n",
    "            dt_monst = pd.to_datetime(f'{st}01').date()\n",
    "            dt_moned = dt_monst + relativedelta(months=1)\n",
    "            if dt_moned <= start_date.value or dt_monst > end_date.value:\n",
    "                continue\n",
    "            df = pd.read_csv(fp,header=None).rename(columns={0:'timestamp',1:'tradp'})[['tradp','timestamp']]\n",
    "            df.loc[:,'timestamp'] = pd.to_datetime(df['timestamp'],format='%Y%m%d %H%M%S%f')\n",
    "            df = df[(df['timestamp'].apply(lambda x:x.date()) >= start_date.value) & (df['timestamp'].apply(lambda x:x.date()) <= end_date.value)]\n",
    "            df.loc[:,'tradp'] = 10000 * df['tradp']\n",
    "            dfs.append(df)\n",
    "            \n",
    "        \n",
    "        \n",
    "    alldf = pd.concat(dfs)\n",
    "    alldf = alldf.sort_values('timestamp') #.sort_index()\n",
    "    logger.info('loading done ')\n",
    "    if auto_make_tri_mode:\n",
    "        count = 0\n",
    "        last_bucket_idx = 0\n",
    "        # dist = dict()\n",
    "        dist = Counter(adf['tradp'])\n",
    "        # balanced_tri_dict = list()\n",
    "        # can_form_tri = False\n",
    "        last_mid = 0\n",
    "        for idx,prc in enumerate(alldf['tradp']):\n",
    "            count +=1    \n",
    "            # at least 5 trades form a J\n",
    "            # if len(dist.keys()) > 2:\n",
    "            #     can_form_tri = True\n",
    "\n",
    "            # print(v)\n",
    "            # prc = v.tradp\n",
    "            \n",
    "            # if prc not in dist.keys():\n",
    "            #     dist[prc] = 1\n",
    "            # else:\n",
    "            #     dist[prc] += 1\n",
    "            \n",
    "            # if len(pp.keys()) > lastklen:\n",
    "            #     print(list(zip(pp.keys(),pp.values())))\n",
    "            #     lastklen = len(pp.keys())\n",
    "\n",
    "\n",
    "            # cal tri endpoints and plot\n",
    "            balanced_prc = -1\n",
    "            balanced_cnt = -1\n",
    "            # find max counts' price level\n",
    "            for _prc,_cnt in dist.items():\n",
    "                if _cnt > balanced_cnt:\n",
    "                    balanced_cnt = _cnt\n",
    "                    balanced_prc = _prc\n",
    "\n",
    "\n",
    "            up_p = max(dist.keys())\n",
    "            dn_p = min(dist.keys())\n",
    "\n",
    "            dn_p_m = balanced_prc - (up_p - balanced_prc)\n",
    "            up_p_m = balanced_prc + (balanced_prc - dn_p)\n",
    "\n",
    "            up_m_gap = up_p_m - up_p\n",
    "            dn_m_gap = dn_p - dn_p_m\n",
    "            th = 0.005\n",
    "\n",
    "            sigma_cnt = sum(dist.values())\n",
    "            tri_area_up = balanced_cnt * (up_p-balanced_prc)\n",
    "            tri_area_dn = balanced_cnt * (balanced_prc -  dn_p)\n",
    "            if 'sym_tri' ==  auto_make_tri_mode:\n",
    "                cond = abs(up_m_gap) <= th and abs(dn_m_gap) <= th and up_p != balanced_prc and balanced_prc != dn_p and abs(balanced_prc - last_mid) > 0.01\n",
    "            elif 'tri_done' == auto_make_tri_mode:\n",
    "                cond = (abs(sigma_cnt -  tri_area_up) < 5 or abs(sigma_cnt - tri_area_dn) < 5) and sigma_cnt > 5\n",
    "            # if :\n",
    "            #     print(f'up tri fullfillment')\n",
    "            # elif :\n",
    "            #     print(f'dn tri fullfillment')\n",
    "\n",
    "            if cond:\n",
    "            # or count % 10000 == 0\n",
    "            # :\n",
    "                logger.info(f'count:{count:10d} mirror to DN:{dn_p:10.2f} Mid:{balanced_prc:10.2f} UP:{up_p:10.2f} DN:{dn_p:10.2f} '\n",
    "                      f'M_UP:{up_p_m:10.2f} M_DN:{dn_p_m:10.2f} upGap:{up_m_gap:10.2f} dnGap:{dn_m_gap:10.2f}')\n",
    "                # add to bucket\n",
    "                _key = alldf['timestamp'].iloc[last_bucket_idx].strftime('%Y%m%d_%H%M%S') + '-'+alldf['timestamp'].iloc[idx].strftime('%Y%m%d_%H%M%S')\n",
    "                logger.info(f'_key:{_key}')\n",
    "                time_chains_dict[_key] = alldf.iloc[last_bucket_idx:idx+1,:].values\n",
    "                \n",
    "                last_bucket_idx = idx+1\n",
    "                count = 0\n",
    "                last_mid = balanced_prc\n",
    "                dist = dict()\n",
    "                # break\n",
    "        # add last bucket\n",
    "        _key = alldf['timestamp'].iloc[last_bucket_idx].strftime('%Y%m%d_%H%M%S') + '-'+alldf['timestamp'].iloc[idx].strftime('%Y%m%d_%H%M%S')\n",
    "        logger.info(f'_key:{_key}')\n",
    "        time_chains_dict[_key] = alldf.iloc[last_bucket_idx:idx+1,:].values\n",
    "    else:\n",
    "        # resample to min...\n",
    "        # group by 1min    \n",
    "        _dtr = dtsampler(alldf['timestamp'], sample_min_slider.value,)\n",
    "        # _dtr =alldf['timestamp'].apply(lambda dt:dt.date())\n",
    "        last_bp = None \n",
    "        print(_dtr[:5],)\n",
    "        vfs = list()\n",
    "        last_k = None\n",
    "        _count = 0\n",
    "        for k,subdf in alldf.groupby(_dtr):\n",
    "            _count+=1\n",
    "            if _count % 100 ==0:\n",
    "                logger.info(f'{_count} comb: k:{k} lask:{last_k}')\n",
    "            balanced_prc,_ = get_bp(subdf.tradp.values)\n",
    "            \n",
    "            if last_bp is None:\n",
    "                last_k = k\n",
    "                last_bp = balanced_prc\n",
    "                vfs.append(subdf.tradp.values)\n",
    "            else:\n",
    "                # using ratio to combine range\n",
    "                if abs(balanced_prc/last_bp-1) < comb_range_slider.value/1000:\n",
    "                    vfs.append(subdf.tradp.values)\n",
    "                    # new_df = pd.concat(dfs,ignore_index=True,copy=False)\n",
    "                    new_vector = np.concatenate(vfs)\n",
    "                    new_bp,_ = get_bp(new_vector)\n",
    "                    last_bp = new_bp\n",
    "                else:                   \n",
    "                    # old combined and init new bp\n",
    "                    # new_df = pd.concat(dfs,ignore_index=True,copy=False)\n",
    "                    new_vector = np.concatenate(vfs)\n",
    "                    time_chains_dict[last_k] = new_vector\n",
    "                    # reinit vfs\n",
    "                    vfs = list()\n",
    "                    last_k = k\n",
    "                    last_bp = balanced_prc\n",
    "                    vfs.append(subdf.tradp.values)\n",
    "        # the last segments\n",
    "        new_vector = np.concatenate(vfs)\n",
    "        time_chains_dict[last_k] = new_vector\n",
    "                    \n",
    "                    \n",
    "            \n",
    "            # break\n",
    "    \n",
    "    time_chain_ts = sorted(list(time_chains_dict.keys()))\n",
    "    range_list.options = time_chain_ts\n",
    "    range_list.value = list()\n",
    "    \n",
    "    # store current figure param\n",
    "    time_chains_key_list = list()\n",
    "    # store for triangle starts X, for SpanSelector\n",
    "    last_dist_starts = list()\n",
    "    redo_list = list()\n",
    "    \n",
    "    refresh_plots(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe70eb99-18c8-4c76-b02e-d525b6edab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "underlying_list.observe(on_select_inst,names='value')\n",
    "resample_but.on_click(lambda b:on_select_inst(underlying_list.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a8e3d79-0d4b-47ea-8c34-20bd9946f77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_redo(b):\n",
    "    # global redo_list,time_chains_key_list,last_dist_starts\n",
    "    if len(redo_list) > 1:\n",
    "        refresh_plots('redo')\n",
    "    else:\n",
    "        logger.error(f\"CANNOT REDO!!!\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70d2307-ebc3-463b-af61-78a5a54495d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5ad8c3b8-c979-48b9-a968-62ea8a5540e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c010edee8e94c7aa38ccea723b06598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Accordion(children=(Textarea(value='', layout=Layout(border_bottom='1px solid black', border_leâ€¦"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17936fa5-e2a7-4264-9f5f-e04dbdd2e7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
